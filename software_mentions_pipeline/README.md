```
software_mention_pipeline/
â”œâ”€â”€ load_inputs.py               # Load corpus + software metadata, init DB
â”œâ”€â”€ batch_filter.py              # Stage 1: extract exact/fuzzy matches
â”œâ”€â”€ feature_builder.py           # Stage 2â€“3: embeddings + heuristic features
â”œâ”€â”€ run_ner_models.py            # Stage 4: NER labeling from Indus, etc.
â”œâ”€â”€ score_and_rank.py            # Stage 5: XGBoost classifier + DB write
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ corpus.jsonl             # Input paper corpus (3 GB)
â”‚   â”œâ”€â”€ ontosoft.json            # OntoSoft software metadata
â”‚   â”œâ”€â”€ ascl.json                # ASCL metadata
â”‚   â””â”€â”€ match_candidates.db      # SQLite DB with all results
```

---

### âš™ï¸ Setup
```bash
pip install -r requirements.txt
```
Add to `requirements.txt`:
```txt
transformers
sentence-transformers
xgboost
scikit-learn
pandas
joblib
```

---

### ğŸš€ Pipeline Execution
Run each step in sequence:
```bash
python load_inputs.py
python batch_filter.py
python feature_builder.py
python run_ner_models.py
python score_and_rank.py
```

---

### ğŸ§ª Notes
- `score_and_rank.py` requires a column `final_classification` with labels to train
- Add these manually or use `labeling_tool.py` (see below)
- You can re-run classification after model training to populate predictions

---

### ğŸ›  SQLite Schema (`candidates` table)
| Column              | Description                         |
|---------------------|-------------------------------------|
| bibcode             | Paper ID                            |
| title, abstract     | Metadata from the paper             |
| label               | Matched software label              |
| match_type          | "exact" or "fuzzy"                  |
| context             | ~50-word snippet around match       |
| context_score       | Embedding sim: context â†” label desc |
| abstract_score      | Embedding sim: abstract â†” desc      |
| has_heuristics      | 1 if context contains software terms|
| ner_indus           | NER result from Indus               |
| ner_multidomain     | NER result from multidomain model   |
| final_classification| Manual or predicted match label     |

---

### ğŸ– `labeling_tool.py` (planned)
This module will:
- Load candidates from DB where `final_classification IS NULL`
- Display context and label, and accept human input (`likely`, `uncertain`, `false`)
- Write decisions back to the DB

---